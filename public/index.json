[
{
	"uri": "/",
	"title": "Adding watermark to image uploaded to Amazon S3 using AWS Lambda",
	"tags": [],
	"description": "",
	"content": "Adding watermark to new image uploaded to Amazon S3 using AWS Lambda Overview Dynamic data transformations are very common nowadays. For different applications and workloads, we often need the ability to modify the data as necessary for each use case. In this workshop, I will demonstrate how we can use AWS Lambda for a simple task such as adding a watermark to the images every time they are uploaded to an Amazon S3 bucket. This can be further expanded to every tasks that demand object modification operations before storing in S3 buckets. I will go through every step from creating all the resources needed, testing the function, and then cleaning up. Let’s get started!\nContent Introduction Creating the S3 bucket Creating IAM role for Lambda function Creating and packaging Lambda function Testing the function Resource Cleanup "
},
{
	"uri": "/4-packaginglambda/4.1-createlambda/",
	"title": "Create a Lambda Function",
	"tags": [],
	"description": "",
	"content": "Create a Lambda function Access the AWS Management Console interface: Look for Lambda and click on the service icon to go to the Lambda Console. Within the Lambda console interface: Click on Create a function On the Create function window: Choose Author from scratch as the method\nFor Basic information, enter the name of the Lambda function as WatermarkS3Upload\nFor Runtime, choose the version of your Python environment.\nMake sure you got the runtime version the same as your environment, otherwise the function may not work.\nNext, expand Change default execution role, select Use an existing role\nFrom the dropdown, select the IAM Role we have created in the previous step LambdaWatermarkS3Role\nWe now can move on by clicking Create function\nSuccessfully created function Next up, we\u0026rsquo;re going to create the trigger for our lambda function\n"
},
{
	"uri": "/3-createiamrole/3.1-createiampolicy/",
	"title": "Create IAM Policy",
	"tags": [],
	"description": "",
	"content": "Create IAM Policy Access the AWS Management Console interface: Look for IAM and click on the service to go to the IAM Console. Within the IAM console interface: On the right menu, locate and click on Policies\nThen click on Create Policy\nFollow these steps to create an IAM Policy that allows access to CloudWatch Logs and the S3 bucket we\u0026rsquo;ve created: On the Specify Permissions window, choose JSON for our policy editor.\nYou can also use the Visual Editor to specify permission but it is usually prone to mistakes, so review carefully before creating policy.\nCopy the JSON policy below to the clipboard.\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;logs:CreateLogStream\u0026#34;, \u0026#34;logs:CreateLogGroup\u0026#34;, \u0026#34;logs:PutLogEvents\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; }, { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;s3:*\u0026#34;, \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:s3:::YOUR-BUCKET-NAME\u0026#34;, \u0026#34;arn:aws:s3:::YOUR-BUCKET-NAME/*\u0026#34; ] } ] } Replace YOUR-BUCKET-NAME with the actual name of your bucket that you\u0026rsquo;ve copied before.\nClick on Next\nEnter the policy name as LambdaWatermarkS3\nReview the policy permission and click on Create policy\nCompleted the process of creating the IAM Policy In the policy list, filter by name LambdaWatermarkS3 or by type Customer managed, you should find the new policy has been created\nNext, let\u0026rsquo;s create an IAM Role and attach this policy.\n"
},
{
	"uri": "/1-introduction/",
	"title": "Introduction",
	"tags": [],
	"description": "",
	"content": "Introduction Solution Overview Creating the S3 bucket\nIn this step, we will create our S3 Bucket. Inside, there will be two folders (prefixes) for source (unprocessed) and destination (added some watermark) images for demonstration.\nCreating an IAM role for the Lambda function\nThen we will create an IAM role that has the needed permissions for the Lambda function to have access to S3 for object processing and CloudWatch Logs for writing logs.\nCreating and packaging the Lambda function\nAnd we will create our Lambda function for processing the images. We will package our function with an external library for image processing and upload to AWS.\nTesting the function\nAfter finishing creating the resources, we will test if the function works by uploading sample images.\nResource Cleanup\nCleanup.\nLet’s get started by logging in to the AWS console with your AWS account, it’s best to use an IAM Account with admin access, and then pick a region. I will use the ús-east-1 (N.Virginia) region in this workshop.\n"
},
{
	"uri": "/3-createiamrole/3.2-createiamrole/",
	"title": "Create IAM Role",
	"tags": [],
	"description": "",
	"content": "Create IAM Role Back to the IAM Console: On the right menu, locate and click on Roles\nThen click on Create Role\nIn the Create role Interface: For section Select trusted entity choose AWS Service.\nFor Use Case select Lambda from the dropdown.\nAttach IAM Policy: In the Add Permission section, filter the policies just like we did before and select LambdaWatermarkS3 to attach. Click on Next Name and create IAM Role Next, name the role as LambdaWatermarkS3Role Review and click on Create Role\nFinish Creating IAM Role\nGreat, now let\u0026rsquo;s go ahead and create our Lambda function.\n"
},
{
	"uri": "/4-packaginglambda/4.2-createtrigger/",
	"title": "Create the S3 Trigger",
	"tags": [],
	"description": "",
	"content": "Add a trigger for the Lambda function On the new Lambda function console Look for Add Trigger and click on it. Within the Add Trigger interface: Select S3 as the source from the dropdown Next, in Bucket choose the bucket we have created before from the dropdown.\nFor Event types select All object create events\nWe will listen to trigger on the object created on the prefix \u0026ldquo;source/\u0026rdquo; so type \u0026ldquo;source/\u0026rdquo; for Prefix\nBecause we\u0026rsquo;ve purposely created two prefixes and listened to events triggered from the source/ prefix, we will avoid repetitive Lambda calls for object creation by making sure the Lambda function will post the object to the destination/ prefix in the S3 bucket.\nOnce you\u0026rsquo;ve done configuring, click on Add\nWe\u0026rsquo;ve successfully created an S3 trigger for our function Great! Now we will start implementing and packaging the function.\n"
},
{
	"uri": "/2-creates3bucket/",
	"title": "Creating the S3 bucket",
	"tags": [],
	"description": "",
	"content": "Overview In this section, we will start creating our bucket for testing, we will add two prefixes named source/ and destination/ in the bucket to act as folders inside the bucket for demonstration.\nThe source/ folder will be for storing the source, unedited images that we\u0026rsquo;ve uploaded, and the destination/ folder will store images with a watermark after modification.\nAmazon S3 has a flat structure instead of a hierarchy like you would see in a file system. However, for organizational simplicity, the Amazon S3 console supports the folder concept as a means of grouping objects by using a shared name prefix for the grouped objects.\nCreating the bucket In the AWS console home page: Navigate to the search bar, type S3, and click on the service.\nIn the S3 console click on Create Bucket\nIn the create bucket window: Choose your preferred region for our S3 Bucket\nEnter the name for the S3 bucket, make sure it follows the bucket naming scheme and is globally unique, I will name my bucket lambda-watermark-bucket-_randomnumber_\nWe can leave the settings as default for simplicity then scroll down and click on Create Bucket\nWait for the success message from the console to make sure the bucket is created successfully.\nYou can copy the bucket name and ARN and put it in the clipboard or somewhere for later steps.\nCreating the folders Back in S3 console: Go to the bucket we\u0026rsquo;ve just created by clicking on it from the bucket list. Now we can start creating folders\nClick on Create Folder\nEnter \u0026ldquo;source\u0026rdquo; as the name for the folder.\nWe can leave the settings as default and then click on Create Folder\nRepeat the creating folder process for our \u0026ldquo;destination\u0026rdquo; folder, it will store images with a watermark after modification. Go back and your bucket structure will look something like this:\nGreat, now you have created the S3 bucket successfully! Move on to the next step.\n"
},
{
	"uri": "/3-createiamrole/",
	"title": "Creating an IAM role for Lambda function",
	"tags": [],
	"description": "",
	"content": "Lambda Permissions Our Lambda function will need permissions to be able to download, modify, and upload the image in the S3 bucket. Writing logs in Cloudwatch Logs permission is also a necessary task for logging and monitoring each execution.\nThe best way to do it is by giving the Lambda function an IAM Role. In this section, I\u0026rsquo;ll show you how to give the Lambda function which will be created later the permissions needed for the workshop task, using an IAM Role.\nWe\u0026rsquo;ll start by creating a new custom IAM Policy then after creating a new IAM Role and attach it to the managed policy.\nContent Create IAM Policy Create IAM Role "
},
{
	"uri": "/4-packaginglambda/4.3-packagelambda/",
	"title": "Package the Lambda function",
	"tags": [],
	"description": "",
	"content": "Function Code On your local machine: Create a new directory, I\u0026rsquo;ll name it workshop1, you can choose any name you want.\nInside the directory create a Python file and name it lambda_function.py for our function.\nCopy the code below and paste it inside the file you\u0026rsquo;ve just created:\nfrom PIL import Image, ImageDraw, ImageFont import boto3 import os s3 = boto3.client(\u0026#39;s3\u0026#39;) def add_text_watermark(image_path): watermark_text = \u0026#34;SAMPLE\u0026#34; image = Image.open(image_path) draw = ImageDraw.Draw(image) w, h = image.size x, y = int(w / 2), int(h / 2) font = ImageFont.load_default(size=30) draw.text((x, y), watermark_text, fill=(255, 255, 255), font=font, anchor=\u0026#39;ms\u0026#39;) image.save(image_path) image.close() def lambda_handler(event, context): # Extract the bucket name and key from the event bucket = event[\u0026#39;Records\u0026#39;][0][\u0026#39;s3\u0026#39;][\u0026#39;bucket\u0026#39;][\u0026#39;name\u0026#39;] key = event[\u0026#39;Records\u0026#39;][0][\u0026#39;s3\u0026#39;][\u0026#39;object\u0026#39;][\u0026#39;key\u0026#39;] # Define the download path in the Lambda temporary directory and the upload path download_path = \u0026#39;/tmp/\u0026#39; + os.path.basename(key) upload_key = \u0026#39;destination/\u0026#39; + os.path.basename(key) # Save watermarked images in \u0026#39;destination\u0026#39; folder # Download the image from the \u0026#39;source\u0026#39; folder source_key = \u0026#39;source/\u0026#39; + os.path.basename(key) s3.download_file(bucket, source_key, download_path) # Add a watermark to the image add_text_watermark(download_path) # Upload the watermarked image to the \u0026#39;destination\u0026#39; folder s3.upload_file(download_path, bucket, upload_key) # Clean up the temporary file os.remove(download_path) return { \u0026#39;statusCode\u0026#39;: 200, \u0026#39;body\u0026#39;: \u0026#39;Watermark added successfully!\u0026#39; } This add_text_watermark function is a simple function using PIL that adds a white text watermark \u0026ldquo;SAMPLE\u0026rdquo; into the image and returns it.\nIn general, the Lambda function will extract the event key and download the image with the \u0026ldquo;source/\u0026rdquo; prefix every time the user uploads an image object with this prefix in the S3 bucket. Then it will call the add_text_watermark function to add a watermark and then replace the source/ prefix with the destination/ prefix to add the edited image to the bucket.\nWe will need to install PIL inside the directory so that the function can call methods in the library. Inside the same directory of your lambda_function.py , run the command pip install -t . pillow. Pip will collect the pillow library inside the current directory, your directory now should look something like this: Now compress the directory into a single zip file by running the command zip -r ./my_package.zip . whereas my_package is the name of your .zip file that we\u0026rsquo;ll be uploaded to our lambda function\nMake sure again that your .zip file has a flat directory structure, with your function\u0026rsquo;s handler code and all your dependency folders installed at the root.\nAfter you got the .zip package ready on your machine, go back to the Lambda console Click on the new Lambda function on the list we\u0026rsquo;ve just created. Click on Upload from then .zip file and select the my_package.zip file from your machine, wait for it to upload successfully and we will move on and test the function in the next step. "
},
{
	"uri": "/4-packaginglambda/",
	"title": "Creating and packaging Lambda function",
	"tags": [],
	"description": "",
	"content": "Overview In this step, we will start by creating the function code using Python. For the task of modifying image objects, we often need a dedicated library for image processing, we will package the function with an external library called PIL, following this documentation Working with .zip file archives for Python Lambda functions.\nMake sure you have your Python environment and pip on your local machine to begin. I will be using Python 3.8 on my Ubuntu machine, you will also need to note down your Python version on your machine.\nFor different operating systems, the concepts are basically the same but the process will be a small differences. I will demonstrate the process using Ubuntu.\nContent Create Lambda function Create S3 Trigger Package Lambda Function "
},
{
	"uri": "/5-testing/",
	"title": "Testing the function",
	"tags": [],
	"description": "",
	"content": "Testing the function AWS Lambda supports function testing with event creation inside the console, but with this simple process, we can just test the function by uploading some images to the source folder in our S3 bucket and seeing the result in the destination folder.\nI\u0026rsquo;ve prepared some .jpg images on my machine. You can put in any type of image that the PIL library supports, any error (including incompatible image file type) in the execution of the Lambda function will be logged into a CloudWatch Log group.\nFrom the AWS console, go back to S3.\nLocate and select the bucket that we\u0026rsquo;ve created in this workshop.\nLocate and click on the source/ folder to go inside the folder Choose Upload In the Upload window, select Add files Choose an image file or multiple image files that you want to upload in the file by choosing in the popup window\nGo back to the bucket You can just check the result images by clicking on the destination folder, the images should have the same name as you\u0026rsquo;ve uploaded. Select the image object to view details Click Download, now you can open the image and it should have the watermark inside. Image in the source folder After Lambda invocation, in the destination folder Checking the logs One more thing, you should also take a look at the log files that have been created for every Lambda invocation to inspect the operation.\nLook for CloudWatch in the search bar of your AWS Console In the left menu, expand Logs then select Log group\nYou should see the Log group with the prefix aws/lambda/ plus our function name WatermarkS3Upload if you completed all the previous steps. Click on it Select the latest log group and expand the logs to explore. My function logs That\u0026rsquo;s it, you\u0026rsquo;ve basically finished this workshop. Now let\u0026rsquo;s go ahead and delete the resources to restore your account to the state it was in to avoid unwanted charges.\n"
},
{
	"uri": "/6-cleanup/",
	"title": "Clean up resources",
	"tags": [],
	"description": "",
	"content": "Clean up resources We will proceed to delete the resources in the following order:\nDelete the Lambda function Access the AWS Lambda console.\nSelect the function we\u0026rsquo;ve created.\nExpand Action and click Delete\nConfirm deletion. Delete the S3 Bucket Access S3 in the AWS console.\nSelect the bucket we\u0026rsquo;ve created.\nClick Empty\nConfirm object deletion Go back to the bucket\nChoose Delete Confirm bucket deletion Delete the IAM Policy Access IAM in the AWS console.\nOn the left menu, click Policies\nFilter to select the Policy we\u0026rsquo;ve created LambdaWatermarkS3\nClick Delele Confirm deletion Delete the IAM Role Back to IAM in the AWS console.\nOn the left menu, click Roles\nFilter to select the IAM role we\u0026rsquo;ve created LambdaWatermarkS3Role\nClick Delele Confirm deletion Thank you for taking your time to finish this workshop!!!\n"
},
{
	"uri": "/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]